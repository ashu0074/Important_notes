Some Important function used 

#####################################################
Groupby & Merge


a) groupby and counts and reset the index

num_rating_df = rating_with_name.groupby('Book-Title').count()['Book-Rating'].reset_index()
num_rating_df.rename(columns = {'Book-Rating':'num_ratings'},inplace = True)
num_rating_df

b) groupby and mean and reset the index
avg_rating_df = rating_with_name.groupby('Book-Title').mean()['Book-Rating'].reset_index()
avg_rating_df.rename(columns = {'Book-Rating':'avg_rating'},inplace = True)
avg_rating_df



#####   "# remove the outlier of rate_per_sqft"
******************************
1)

def remove__rps_outliers(df):
    df_out = pd.DataFrame()
    for key,subdf in df.groupby('location'):  # groupby on the basis of location 
        m = np.mean(subdf.rate_per_sqft)     # mean
        st = np.std(subdf.rate_per_sqft)     # standard deviation
        reduced_df = subdf[(subdf.rate_per_sqft>(m-st)) & (subdf.rate_per_sqft < (m+st))]
        df_out = pd.concat([df_out,reduced_df],ignore_index=True)
    return df_out


df7 = remove__rps_outliers(df6)
df7.shape
************************
2)

#####   "# from the location we plot the graph on the bh2 and bhk3"
***********
import matplotlib.pyplot as plt

def plot_scatter_chart(df,location):
    bhk2 = df[(df.location == location) & (df.BHK ==2)]
    bhk3 = df[(df.location == location) & (df.BHK ==3)]
    matplotlib.rcParams['figure.figsize'] = (15,10)
    
    plt.scatter(bhk2.total_sqft, bhk2.price, color='Blue', label = '2 Bhk', s = 50)
    plt.scatter(bhk3.total_sqft, bhk3.price, color = 'green', marker = '+',label = '3 Bhk',s = 50)
    plt.xlabel("total Square Foot")
    plt.ylabel('Price')
    plt.title(location)
    plt.legend()
    *******************
    
    ###### Remove the bhk outlier
    
******************
3)

def remove_bhk_outliers(df):
    exclude_indices=np.array([])
    for location, location_df in df.groupby('location'):
        bhk_sats={}
        for BHK,BHK_df in location_df.groupby('BHK'):
            bhk_sats[BHK]={
                'mean':np.mean(BHK_df.price_per_sqft),
                'std':np.std(BHK_df.price_per_sqft),
                'count':BHK_df.shape[0]
            }
        for BHK,BHK_df in location_df.groupby('BHK'):
            stats=bhk_sats.get(BHK-1)
            if stats and stats['count']>5:
                exclude_indices=np.append(exclude_indices,BHK_df[BHK_df.price_per_sqft<(stats['mean'])].index.values)
    return df.drop(exclude_indices,axis='index')
df8=remove_bhk_outliers(df7)
df8.shape
***************************************

############"Grid Search CV"
4)

from sklearn.model_selection import GridSearchCV

from sklearn.linear_model import Lasso
from sklearn.tree import DecisionTreeRegressor

def find_best_model_using_gridsearchcv(X,y):
    algos = {
        'linear_regression':{
            'model': LinearRegression(),
            'params':{
                'normalize':[True,False]
            }
        },
        'lasso':{
            'model':Lasso(),
            'params':{
                'alpha':[1,2],
                'selection':['random','cyclic']
            }
        },
        'decision_tree':{
            'model':DecisionTreeRegressor(),
            'params':{
                'criterion':['mse','friedman_mse'],
                'splitter':['best','random']
            }
        }
    }
    
    score = []
    cv = ShuffleSplit(n_splits = 5, test_size = 0.2, random_state = 0)
    for algo_name, config in algos.items():
        gs = GridSearchCV(config['model'], config['params'],cv = cv, return_train_score = False)
        gs.fit(X,y)
        score.append({
            'model':algo_name,
            'best_score':gs.best_score_,
            'best_params':gs.best_params_
        })
        
    return pd.DataFrame(score,columns=['model','best_score','best_params'])

find_best_model_using_gridsearchcv(X,y)

********************************************************
5)

def price_predict(location,sqft,bath,BHK):
    loc_index = np.where(X.columns == location)[0][0]    # you to find the location -- it give "Index" 
    x = np.zeros(len(X.columns))
    x[0]=sqft
    x[1]=bath
    x[2]=BHK
    if loc_index >=0:
        x[loc_index] = 1                                # once we know the location we set value index =1
    return model.predict([x])[0]
    
*****************************************************
  
 6)
  *********************************** Merge the two data**********************************
    eg:- movies and credits are two 2 dataframe and we want ot merge on the bases of "credit"

### movies = movies.merge(credits, on = 'title')###########

*******************************************************************
7)

'[{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"}, {"id": 878, "name": "Science Fiction"}]'


def convert(obj):
    L = []
    for i in ast.literal_eval(obj):
        L.append(i['name'])
    return L

**  
movies['genres'] = movies['genres'].apply(convert) 

output:-
0       [Action, Adventure, Fantasy, Science Fiction]
1                        [Adventure, Fantasy, Action]
2                          [Action, Adventure, Crime]
3                    [Action, Crime, Drama, Thriller]

**********************************************************************************

8) 
[{"cast_id": 242, "character": "Jake Sully", "credit_id": "5602a8a7c3a3685532001c9a", "gender": 2, "id": 65731, "name": "Sam Worthington", "order": 0}, {"cast_id": 3, "character": "Neytiri", "credit_id": "52fe48009251416c750ac9cb", "gender": 1, "id": 8691, "name": "Zoe Saldana", "order": 1}, {"cast_id": 25, "character": "Dr. Grace Augustine", "credit_id": "52fe48009251416c750aca39", "gender": 1, "id": 10205, "name": "Sigourney Weaver", "order": 2}, {"cast_id": 4, "character": "Col. Quaritch", "credit_id": "52fe48009251416c750ac9cf", "gender": 2, "id": 32747, "name": "Stephen Lang", "order": 3}]

* In this we want to pull outer only 3 dictionary  

def convert3(obj):
    L = []
    counter = 0
    for i in ast.literal_eval(obj):
        if counter <3:
            L.append(i['name'])
            counter += 1
    return L
    
movies['cast'] = movies['cast'].apply(convert3)

********************************************
9)  In crew i want to extract only those dictionary --- job -"director " and i want the extract the name from the distonary.

def fetch_director(obj):
    L = []
    for i in ast.literal_eval(obj):
        if i['job'] == 'Director':
            L.append(i['name'])
            break
    return L
    
movies['crew'] = movies['crew'].apply(fetch_director)

*******************************************************************
10) * In this we have to remove space b/w Entity 
* eg :- Sam Worthington  ---> SamWorthington  we consider into single entity otherwise it contain 2 entity --> Sam and Worthington
*  In some case may conflict we have other person name with same intial eg --> Sam Luies---> Sam and Luies and at that point
* when we want to fetch sam --> it give both Sam Worthington, Sam Luies 
* so colab and make them into single entity.


######  Convert ---    " " ->""

movies['genres'] = movies['genres'].apply(lambda x:[i.replace(" ","") for i in x])
or

def collapse(L):
    L1 = []
    for i in L:
        L1.append(i.replace(" ",""))
    return L1



movies['cast'] = movies['cast'].apply(collapse)
movies['crew'] = movies['crew'].apply(collapse)
movies['genres'] = movies['genres'].apply(collapse)
movies['keywords'] = movies['keywords'].apply(collapse)

************************************************************

Recomdedation on the bases of index postion 





def recommend(movie):
    index = new_df[new_df['title']== movie].index[0]
    distances = sorted(list(enumerate(similarity[index])), reverse=True, key = lambda x:x[1])
    for i in distances[1:6]:                                                     
        print(new_df.iloc[i[0]].title)
    
     ***********************************************************************
    
    
    
* recommended for the movies on the bases of index position

def recommend(book_name):
    # index fetch
    index = np.where(pt.index==book_name)[0][0]
    similar_items = sorted(list(enumerate(similarity_scores[index])),key=lambda x:x[1],reverse=True)[1:5]
    
    data = []
    for i in similar_items:
        item = []
        temp_df = books[books['Book-Title'] == pt.index[i[0]]]
        item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Title'].values))
        item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Author'].values))
        item.extend(list(temp_df.drop_duplicates('Book-Title')['Image-URL-M'].values))
        
        data.append(item)
    
    return data
*********************************************************************************







   
